---
title: "7-iml"
author: "Bernard"
date: "2021-12-02"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


```{r, include = FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

# Load package

```{r}

# Helper
library(tidyverse)
library(data.table)
library (cowplot)
library (officer)
library (flextable)
library (dataPreparation)
# ML
library (MASS)# Step AIC
library (ncvreg)
library (abess)# Best subset regression
library (glmnet) # Lasso
library (mboost) 
library (earth) # mars
library (SignifReg)
# Parallel
library (future)

# P value custom

p_extract <- function (x) {
    
    p <- x[2, "Pr(>Chi)"]
    return (p)
}

performance <- function (y_pred, y_true) {
  
  c("Accuracy" = MLmetrics::Accuracy(y_pred, y_true),
    "AUC" = MLmetrics::AUC(y_pred, y_true),
    "Precision" = MLmetrics::Precision(y_true, y_pred, positive = NULL),
    "Sensitivity" = MLmetrics::Sensitivity(y_true, y_pred, positive = NULL),
    "Specificity" = MLmetrics::Specificity(y_true, y_pred, positive = NULL))
}
```

# Import

```{r}
# bmr <- readRDS("output/resampling_models.RDS")
# 
# bmr2 <- as.data.table(bmr) %>%
#   mutate (Model = mlr3misc::map (learner, "model"))

dat <- readRDS("output/df.RDS")

np_train <- dat$df_list$np$train_imp[,-1] %>% dplyr::select (-matches ("clinic"))
np_test <- dat$df_list$np$test_imp[,-1]%>% dplyr::select (-matches ("clinic"))
np_dat <- bind_rows(np_train, np_test)

ap_train <- dat$df_list$ap$train_imp[,-1] %>% dplyr::select (-matches ("clinic"))
ap_test <- dat$df_list$ap$test_imp[,-1]%>% dplyr::select (-matches ("clinic"))
ap_dat <- bind_rows(ap_train, ap_test)

dis_train <- dat$df_list$dis$train_imp[,-1]%>% dplyr::select (-matches ("clinic"))
dis_test <- dat$df_list$dis$test_imp[,-1]%>% dplyr::select (-matches ("clinic"))
dis_dat <- bind_rows(dis_train, dis_test)

```

# Neck

## Scaling

```{r}
scales <- build_scales(np_train)
np_train <- fast_scale(np_train, scales = scales)
np_test <- fast_scale(np_test, scales = scales)
```


```{r}
o <- np_test$outcome

# P value

df <- np_train %>% 
  mutate (outcome = as.numeric(outcome) - 1) 


uni_names <- df %>%
  dplyr::select(-outcome) %>%
  map(~glm(df$outcome ~ .x, data = df, family = binomial())) %>% 
  map(anova, test = "Chisq") %>%
  map_dbl(p_extract) %>%
  "<" (0.1) %>%
  which() %>%
  names()

form <- paste0("outcome~", paste0(uni_names, collapse = "+"))

fullmodel <- glm(form, data = df, family = binomial)
nullmodel <- glm(outcome ~1, data = df, family = binomial)

scope = list(lower=formula(nullmodel ),upper=formula(fullmodel))

np_m1 = SignifReg(fullmodel,
                       scope=scope, 
                       alpha = 0.05,
                       direction = "both",
                       criterion = "p-value",
                       adjust.method = "none",
                       trace=FALSE)

p_m1 <- predict (np_m1, type = "response", newdata  = np_test %>% dplyr::select (-outcome))
p_m1 <- ifelse (p_m1 > 0.5, 1, 0)

res_m1 <- performance (y_pred = p_m1,
                       y_true = o)

# Step AIC

full_model <- glm (outcome ~ ., data = df, family = binomial())
np_m2 <- stepAIC (full_model,
                      direction = "both")
summary (np_m2 )

p_m2 <- predict (np_m2, type = "response", newdata  = np_test %>% dplyr::select (-outcome))
p_m2 <- ifelse (p_m2 > 0.5, 1, 0)

res_m2 <- performance (y_pred = p_m2,
                       y_true = o)


# Best subset regression

X_train <-  model.matrix(outcome ~., data = df)[,-1]
Y_train <- as.numeric (df$outcome) 

X_test <-  model.matrix(outcome ~., data = np_test)[,-1]
Y_test <- as.numeric (np_test$outcome) -1

np_m3 <- abess(x = X_train,
                   y = Y_train,
                   family = "binomial", 
                   tune.type = "cv"
                   )

best_np_m3  <- np_m3 [["best.size"]]
print(best_np_m3 )

coef(np_m3 , support.size = best_np_m3 , sparse = FALSE)

p_m3 <- predict (np_m3, type = "response", newx  = X_test, support.size = best_np_m3)
p_m3<- as.numeric (ifelse (p_m3 > 0.5, 1, 0))

res_m3 <- performance (y_pred = p_m3,
                       y_true = Y_test)

# Lasso

np_m4 <- cv.ncvreg(X_train,
                       Y_train,
                       penalty = "lasso",
                       family = "binomial")
plot(np_m4)
coef_np_m4 <- coef(np_m4, s = "lambda.min")[coef(np_m4, s = "lambda.min") != 0]

p_m4 <- predict (np_m4, type = "response", X  = X_test, lambda = np_m4$lambda.min)
p_m4<- ifelse (p_m4 > 0.5, 1, 0)

res_m4 <- performance (y_pred = p_m4,
                       y_true = Y_test)

## Refit lasso
X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_np_m4)]


np_m4_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())


# NCVreg

np_m5 <- cv.ncvreg(X_train,
                     Y_train,
                     type = "MCP",
                     family = "binomial")
plot(np_m5 )
coef_np_m5 <- coef(np_m5, s = "lambda.min")[coef(np_m5, s = "lambda.min") != 0]

p_m5 <- predict (np_m5, type = "response", X  = X_test, lambda = np_m5$lambda.min)
p_m5<- ifelse (p_m5 > 0.5, 1, 0)

res_m5 <- performance (y_pred = p_m5,
                       y_true = Y_test)

## Refit NCVreg
X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_np_m5)]


np_m5_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())
coef(np_m5_refit)

# mboost

df1 <- df %>%
  mutate (outcome = factor (outcome, levels=0:1)) 

np_m6  <- glmboost(outcome ~.,
                      data = df1,
                      control = boost_control(mstop = 1000, nu = 0.1),
                      family = Binomial(type = c("glm"))) # coefficients from Binomial(link = "logit") are 1/2 

# cv10f <- cv(model.weights(np_m6), type = "kfold")

cvm <- cvrisk(np_m6) # , folds = cv10f)
plot (cvm)
np_m6 [mstop(cvm)]

summary (np_m6 [mstop(cvm)])

p_m6 <- predict (np_m6, type = "class", 
                 newdata  = np_test %>% dplyr::select (-outcome))
#p_m6<- ifelse (p_m6 > 0.5, 1, 0)

res_m6 <- performance (y_pred = p_m6,
                       y_true = Y_test)

## Refit mboost

coef_np_m6 <- coef(np_m6)

X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_np_m6)]


np_m6_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())
coef(np_m6_refit)

# MARS - linear

np_m7 <- earth (outcome ~.,
                   data = df,
                   linpreds=TRUE,
                   glm=list(family=binomial))

summary (np_m7)

p_m7 <- predict (np_m7, type = "response", newdata  = np_test %>% dplyr::select (-outcome))
p_m7<- ifelse (p_m7 > 0.5, 1, 0)

res_m7 <- performance (y_pred = p_m7,
                       y_true = Y_test)


```

## Coef

```{r}
coef_np1 <- data.frame (variables = names (coef(np_m1)),
                        pval = coef(np_m1))
coef_np2 <- data.frame (variables = names (coef(np_m2)),
                        stepaic = coef(np_m2))
coef_np3 <- data.frame (variables = rownames (coef(np_m3 , support.size = best_np_m3 , sparse = FALSE)),
                        bestsubset = coef(np_m3 , support.size = best_np_m3 , sparse = FALSE)[,1])
coef_np4 <- data.frame (variables = names (coef(np_m4, s = "lambda.min")[coef(np_m4, s = "lambda.min") != 0]),
                        lasso = coef(np_m4, s = "lambda.min")[coef(np_m4, s = "lambda.min") != 0])
coef_np4_refit <- data.frame (variables = names (coef(np_m4_refit)),
                        lasso_refit = coef(np_m4_refit))
coef_np5 <- data.frame (variables = names (coef(np_m5, s = "lambda.min")[coef(np_m5, s = "lambda.min") != 0]),
                        mcp = coef(np_m5, s = "lambda.min")[coef(np_m5, s = "lambda.min") != 0])
coef_np5_refit <- data.frame (variables = names (coef(np_m5_refit)),
                        mcp_refit = coef(np_m5_refit))
coef_np6 <- data.frame (variables = names (coef(np_m6)),
                        mboost = coef(np_m6))
coef_np6_refit <- data.frame (variables = names (coef(np_m6_refit)),
                        mboost_refit = coef(np_m6_refit))

coef_np7 <- data.frame (variables = names (coef(np_m7)),
                        mars = coef(np_m7))


np_predictors <- data.frame(variables = colnames (X_train)) %>%
  left_join(coef_np1, by = "variables")  %>%
  left_join(coef_np2, by = "variables") %>%
  left_join(coef_np3, by = "variables") %>%
  left_join(coef_np4, by = "variables")%>%
  left_join(coef_np4_refit, by = "variables")%>%
  left_join(coef_np5, by = "variables")%>%
  left_join(coef_np5_refit, by = "variables")%>%
  left_join(coef_np6, by = "variables") %>%
  left_join(coef_np6_refit, by = "variables")%>%
  left_join(coef_np7, by = "variables") %>%
  mutate_all(~ifelse(.x == 0, NA, .x)) %>%
  mutate_if(is.numeric, round, 3) %>%
  mutate (remove = rowSums(is.na(.[,-c(1, 6, 8, 10)])),
          keep = ifelse (remove == 0, "Y", "N"))

np_predictors_best <- np_predictors %>%
  filter (keep == "Y")

```


## Performance

```{r}

np_res <- 
cbind(Model = c("pval", "stepaic", "bestsubset",  "lasso", "ncvreg", "mboost", "mars"), 
      as.data.frame(do.call("rbind", list(res_m1, res_m2, res_m3, res_m4, res_m5, res_m6, res_m7)))
)
```

## Save

```{r}
np_all_models <- list ("pval" = np_m1, 
                       "stepaic" = np_m2, 
                       "bestsubset" = np_m3, 
                       "lasso"= np_m4, 
                       "lasso_refit"= np_m4_refit, 
                       "ncvreg"= np_m5,
                       "ncvreg_refit"= np_m5_refit,  
                       "mboost"= np_m6, 
                       "mboost_refit"= np_m6_refit,
                       "mars"= np_m7)

np <- list (performance = np_res,
            predictors = np_predictors,
            models = np_all_models)

saveRDS(np, "output/np_iml.RDS")
```



# Arm 

## Scaling

```{r}
scales <- build_scales(ap_train)
ap_train <- fast_scale(ap_train, scales = scales)
ap_test <- fast_scale(ap_test, scales = scales)
```


```{r}
o <- ap_test$outcome

# P value

df <- ap_train %>% 
  mutate (outcome = as.numeric(outcome) - 1) 


uni_names <- df %>%
  dplyr::select(-outcome) %>%
  map(~glm(df$outcome ~ .x, data = df, family = binomial())) %>% 
  map(anova, test = "Chisq") %>%
  map_dbl(p_extract) %>%
  "<" (0.1) %>%
  which() %>%
  names()

form <- paste0("outcome~", paste0(uni_names, collapse = "+"))

fullmodel <- glm(formula(form), data = df, family = binomial)
nullmodel <- glm(outcome ~1, data = df, family = binomial)

scope = list(lower=formula(nullmodel ),upper=formula(fullmodel))

ap_m1 = SignifReg(fullmodel,
                       scope=scope, 
                       alpha = 0.05,
                       direction = "both",
                       criterion = "p-value",
                       adjust.method = "none",
                       trace=FALSE)

p_m1 <- predict (ap_m1, type = "response", newdata  = np_test %>% dplyr::select (-outcome))
p_m1 <- ifelse (p_m1 > 0.5, 1, 0)

res_m1 <- performance (y_pred = p_m1,
                       y_true = o)
# Step AIC

full_model <- glm (outcome ~ ., data = df, family = binomial())
ap_m2 <- stepAIC (full_model,
                      direction = "both")
summary (ap_m2 )

p_m2 <- predict (ap_m2, type = "response", newdata  = ap_test %>% dplyr::select (-outcome))
p_m2 <- ifelse (p_m2 > 0.5, 1, 0)

res_m2 <- performance (y_pred = p_m2,
                       y_true = o)


# Best subset regression

X_train <-  model.matrix(outcome ~., data = df)[,-1]
Y_train <- as.numeric (df$outcome) 

X_test <-  model.matrix(outcome ~., data = ap_test)[,-1]
Y_test <- as.numeric (ap_test$outcome) -1

ap_m3 <- abess(x = X_train,
                   y = Y_train,
                   family = "binomial", 
                   tune.type = "cv"
                   )

best_ap_m3  <- ap_m3 [["best.size"]]
print(best_ap_m3 )

coef(ap_m3 , support.size = best_ap_m3 , sparse = FALSE)

p_m3 <- predict (ap_m3, type = "response", newx  = X_test, support.size = best_ap_m3)
p_m3<- as.numeric (ifelse (p_m3 > 0.5, 1, 0))

res_m3 <- performance (y_pred = p_m3,
                       y_true = Y_test)

# Lasso

ap_m4 <- cv.ncvreg(X_train,
                       Y_train,
                       penalty = "lasso",
                       family = "binomial")
plot(ap_m4)
coef_ap_m4 <- coef(ap_m4, s = "lambda.min")[coef(ap_m4, s = "lambda.min") != 0]

p_m4 <- predict (ap_m4, type = "response", X  = X_test, lambda = ap_m4$lambda.min)
p_m4<- ifelse (p_m4 > 0.5, 1, 0)

res_m4 <- performance (y_pred = p_m4,
                       y_true = Y_test)

## Refit lasso
X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_ap_m4)]


ap_m4_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())


# NCVreg

ap_m5 <- cv.ncvreg(X_train,
                     Y_train,
                     type = "MCP",
                     family = "binomial")
plot(ap_m5 )
coef_ap_m5 <- coef(ap_m5, s = "lambda.min")[coef(ap_m5, s = "lambda.min") != 0]

p_m5 <- predict (ap_m5, type = "response", X  = X_test, lambda = ap_m5$lambda.min)
p_m5<- ifelse (p_m5 > 0.5, 1, 0)

res_m5 <- performance (y_pred = p_m5,
                       y_true = Y_test)

## Refit NCVreg
X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_ap_m5)]


ap_m5_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())
coef(ap_m5_refit)

# mboost

df1 <- df %>%
  mutate (outcome = factor (outcome, levels=0:1)) 

ap_m6  <- glmboost(outcome ~.,
                      data = df1,
                      control = boost_control(mstop = 1000, nu = 0.1),
                      family = Binomial(type = c("glm"))) # coefficients from Binomial(link = "logit") are 1/2 

# cv10f <- cv(model.weights(ap_m6), type = "kfold")

cvm <- cvrisk(ap_m6) # , folds = cv10f)
plot (cvm)
ap_m6 [mstop(cvm)]

summary (ap_m6 [mstop(cvm)])

p_m6 <- predict (ap_m6, type = "class", 
                 newdata  = ap_test %>% dplyr::select (-outcome))
#p_m6<- ifelse (p_m6 > 0.5, 1, 0)

res_m6 <- performance (y_pred = p_m6,
                       y_true = Y_test)

## Refit mboost

coef_ap_m6 <- coef(ap_m6)

X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_ap_m6)]


ap_m6_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())
coef(ap_m6_refit)

# MARS - linear

ap_m7 <- earth (outcome ~.,
                   data = df,
                   linpreds=TRUE,
                   glm=list(family=binomial))

summary (ap_m7)

p_m7 <- predict (ap_m7, type = "response", newdata  = ap_test %>% dplyr::select (-outcome))
p_m7<- ifelse (p_m7 > 0.5, 1, 0)

res_m7 <- performance (y_pred = p_m7,
                       y_true = Y_test)


```

## Coef

```{r}
coef_ap1 <- data.frame (variables = names (coef(ap_m1)),
                        pval = coef(ap_m1))
coef_ap2 <- data.frame (variables = names (coef(ap_m2)),
                        stepaic = coef(ap_m2))
coef_ap3 <- data.frame (variables = rownames (coef(ap_m3 , support.size = best_ap_m3 , sparse = FALSE)),
                        bestsubset = coef(ap_m3 , support.size = best_ap_m3 , sparse = FALSE)[,1])
coef_ap4 <- data.frame (variables = names (coef(ap_m4, s = "lambda.min")[coef(ap_m4, s = "lambda.min") != 0]),
                        lasso = coef(ap_m4, s = "lambda.min")[coef(ap_m4, s = "lambda.min") != 0])
coef_ap4_refit <- data.frame (variables = names (coef(ap_m4_refit)),
                        lasso_refit = coef(ap_m4_refit))
coef_ap5 <- data.frame (variables = names (coef(ap_m5, s = "lambda.min")[coef(ap_m5, s = "lambda.min") != 0]),
                        mcp = coef(ap_m5, s = "lambda.min")[coef(ap_m5, s = "lambda.min") != 0])
coef_ap5_refit <- data.frame (variables = names (coef(ap_m5_refit)),
                        mcp_refit = coef(ap_m5_refit))
coef_ap6 <- data.frame (variables = names (coef(ap_m6)),
                        mboost = coef(ap_m6))
coef_ap6_refit <- data.frame (variables = names (coef(ap_m6_refit)),
                        mboost_refit = coef(ap_m6_refit))

coef_ap7 <- data.frame (variables = names (coef(ap_m7)),
                        mars = coef(ap_m7))


ap_predictors <- data.frame(variables = colnames (X_train)) %>%
  left_join(coef_ap1, by = "variables")  %>%
  left_join(coef_ap2, by = "variables") %>%
  left_join(coef_ap3, by = "variables") %>%
  left_join(coef_ap4, by = "variables")%>%
  left_join(coef_ap4_refit, by = "variables")%>%
  left_join(coef_ap5, by = "variables")%>%
  left_join(coef_ap5_refit, by = "variables")%>%
  left_join(coef_ap6, by = "variables") %>%
  left_join(coef_ap6_refit, by = "variables")%>%
  left_join(coef_ap7, by = "variables") %>%
  mutate_all(~ifelse(.x == 0, NA, .x)) %>%
  mutate_if(is.numeric, round, 3) %>%
  mutate (remove = rowSums(is.na(.[,-c(1, 6, 8, 10)])),
          keep = ifelse (remove == 0, "Y", "N"))

ap_predictors_best <- ap_predictors %>%
  filter (keep == "Y")

```


## Performance

```{r}

ap_res <- 
cbind(Model = c("pval", "stepaic", "bestsubset",  "lasso", "ncvreg", "mboost", "mars"), 
      as.data.frame(do.call("rbind", list(res_m1, res_m2, res_m3, res_m4, res_m5, res_m6, res_m7)))
)
```

## Save

```{r}
ap_all_models <- list ("pval" = ap_m1, 
                       "stepaic" = ap_m2, 
                       "bestsubset" = ap_m3, 
                       "lasso"= ap_m4, 
                       "lasso_refit"= ap_m4_refit, 
                       "ncvreg"= ap_m5,
                       "ncvreg_refit"= ap_m5_refit,  
                       "mboost"= ap_m6, 
                       "mboost_refit"= ap_m6_refit,
                       "mars"= ap_m7)

ap <- list (performance = ap_res,
            predictors = ap_predictors,
            models = ap_all_models)

saveRDS(ap, "output/ap_iml.RDS")
```



# Disability

## Scaling

```{r}
scales <- build_scales(dis_train)
dis_train <- fast_scale(dis_train, scales = scales)
dis_test <- fast_scale(dis_test, scales = scales)
```


```{r}
o <- dis_test$outcome

# P value

df <- dis_train %>% 
  mutate (outcome = as.numeric(outcome) - 1)  


uni_names <- df %>%
  dplyr::select(-outcome) %>%
  map(~glm(df$outcome ~ .x, data = df, family = binomial())) %>% 
  map(anova, test = "Chisq") %>%
  map_dbl(p_extract) %>%
  "<" (0.1) %>%
  which() %>%
  names()

form <- paste0("outcome~", paste0(uni_names, collapse = "+"))

fullmodel <- glm(form, data = df, family = binomial)
nullmodel <- glm(outcome ~1, data = df, family = binomial)

scope = list(lower=formula(nullmodel ),upper=formula(fullmodel))

dis_m1 = SignifReg(fullmodel,
                       scope=scope, 
                       alpha = 0.5,
                       direction = "both",
                       criterion = "p-value",
                       adjust.method = "none",
                       trace=FALSE)

p_m1 <- predict (dis_m1, type = "response", newdata  = np_test %>% dplyr::select (-outcome))
p_m1 <- ifelse (p_m1 > 0.5, 1, 0)

res_m1 <- performance (y_pred = p_m1,
                       y_true = o)

# Step AIC

full_model <- glm (outcome ~ ., data = df, family = binomial())
dis_m2 <- stepAIC (full_model,
                      direction = "both")
summary (dis_m2 )

p_m2 <- predict (dis_m2, type = "response", newdata  = dis_test %>% dplyr::select (-outcome))
p_m2 <- ifelse (p_m2 > 0.5, 1, 0)

res_m2 <- performance (y_pred = p_m2,
                       y_true = o)


# Best subset regression

X_train <-  model.matrix(outcome ~., data = df)[,-1]
Y_train <- as.numeric (df$outcome) 

X_test <-  model.matrix(outcome ~., data = dis_test)[,-1]
Y_test <- as.numeric (dis_test$outcome) -1

dis_m3 <- abess(x = X_train,
                   y = Y_train,
                   family = "binomial", 
                   tune.type = "cv"
                   )

best_dis_m3  <- dis_m3 [["best.size"]]
print(best_dis_m3 )

coef(dis_m3 , support.size = best_dis_m3 , sparse = FALSE)

p_m3 <- predict (dis_m3, type = "response", newx  = X_test, support.size = best_dis_m3)
p_m3<- as.numeric (ifelse (p_m3 > 0.5, 1, 0))

res_m3 <- performance (y_pred = p_m3,
                       y_true = Y_test)

# Lasso

dis_m4 <- cv.ncvreg(X_train,
                       Y_train,
                       penalty = "lasso",
                       family = "binomial")
plot(dis_m4)
coef_dis_m4 <- coef(dis_m4, s = "lambda.min")[coef(dis_m4, s = "lambda.min") != 0]

p_m4 <- predict (dis_m4, type = "response", X  = X_test, lambda = dis_m4$lambda.min)
p_m4<- ifelse (p_m4 > 0.5, 1, 0)

res_m4 <- performance (y_pred = p_m4,
                       y_true = Y_test)

## Refit lasso
X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_dis_m4)]


dis_m4_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())


# NCVreg

dis_m5 <- cv.ncvreg(X_train,
                     Y_train,
                     type = "MCP",
                     family = "binomial")
plot(dis_m5 )
coef_dis_m5 <- coef(dis_m5, s = "lambda.min")[coef(dis_m5, s = "lambda.min") != 0]

p_m5 <- predict (dis_m5, type = "response", X  = X_test, lambda = dis_m5$lambda.min)
p_m5<- ifelse (p_m5 > 0.5, 1, 0)

res_m5 <- performance (y_pred = p_m5,
                       y_true = Y_test)

## Refit NCVreg
X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_dis_m5)]


dis_m5_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())
coef(dis_m5_refit)

# mboost

df1 <- df %>%
  mutate (outcome = factor (outcome, levels=0:1)) 

dis_m6  <- glmboost(outcome ~.,
                      data = df1,
                      control = boost_control(mstop = 1000, nu = 0.1),
                      family = Binomial(type = c("glm"))) # coefficients from Binomial(link = "logit") are 1/2 

# cv10f <- cv(model.weights(dis_m6), type = "kfold")

cvm <- cvrisk(dis_m6) # , folds = cv10f)
plot (cvm)
dis_m6 [mstop(cvm)]

summary (dis_m6 [mstop(cvm)])

p_m6 <- predict (dis_m6, type = "class", 
                 newdata  = dis_test %>% dplyr::select (-outcome))
#p_m6<- ifelse (p_m6 > 0.5, 1, 0)

res_m6 <- performance (y_pred = p_m6,
                       y_true = Y_test)

## Refit mboost

coef_dis_m6 <- coef(dis_m6)

X_train_refit <- model.matrix(outcome ~., data = df)[,names(coef_dis_m6)]


dis_m6_refit <- glm.fit(x = X_train_refit,
                       y = Y_train,
                       family = binomial())
coef(dis_m6_refit)

# MARS - linear

dis_m7 <- earth (outcome ~.,
                   data = df,
                   linpreds=TRUE,
                   glm=list(family=binomial))

summary (dis_m7)

p_m7 <- predict (dis_m7, type = "response", newdata  = dis_test %>% dplyr::select (-outcome))
p_m7<- ifelse (p_m7 > 0.5, 1, 0)

res_m7 <- performance (y_pred = p_m7,
                       y_true = Y_test)


```

## Coef

```{r}
coef_dis1 <- data.frame (variables = names (coef(dis_m1)),
                        pval = coef(dis_m1))
coef_dis2 <- data.frame (variables = names (coef(dis_m2)),
                        stepaic = coef(dis_m2))
coef_dis3 <- data.frame (variables = rownames (coef(dis_m3 , support.size = best_dis_m3 , sparse = FALSE)),
                        bestsubset = coef(dis_m3 , support.size = best_dis_m3 , sparse = FALSE)[,1])
coef_dis4 <- data.frame (variables = names (coef(dis_m4, s = "lambda.min")[coef(dis_m4, s = "lambda.min") != 0]),
                        lasso = coef(dis_m4, s = "lambda.min")[coef(dis_m4, s = "lambda.min") != 0])
coef_dis4_refit <- data.frame (variables = names (coef(dis_m4_refit)),
                        lasso_refit = coef(dis_m4_refit))
coef_dis5 <- data.frame (variables = names (coef(dis_m5, s = "lambda.min")[coef(dis_m5, s = "lambda.min") != 0]),
                        mcp = coef(dis_m5, s = "lambda.min")[coef(dis_m5, s = "lambda.min") != 0])
coef_dis5_refit <- data.frame (variables = names (coef(dis_m5_refit)),
                        mcp_refit = coef(dis_m5_refit))
coef_dis6 <- data.frame (variables = names (coef(dis_m6)),
                        mboost = coef(dis_m6))
coef_dis6_refit <- data.frame (variables = names (coef(dis_m6_refit)),
                        mboost_refit = coef(dis_m6_refit))

coef_dis7 <- data.frame (variables = names (coef(dis_m7)),
                        mars = coef(dis_m7))


dis_predictors <- data.frame(variables = colnames (X_train)) %>%
  left_join(coef_dis1, by = "variables")  %>%
  left_join(coef_dis2, by = "variables") %>%
  left_join(coef_dis3, by = "variables") %>%
  left_join(coef_dis4, by = "variables")%>%
  left_join(coef_dis4_refit, by = "variables")%>%
  left_join(coef_dis5, by = "variables")%>%
  left_join(coef_dis5_refit, by = "variables")%>%
  left_join(coef_dis6, by = "variables") %>%
  left_join(coef_dis6_refit, by = "variables")%>%
  left_join(coef_dis7, by = "variables") %>%
  mutate_all(~ifelse(.x == 0, NA, .x)) %>%
  mutate_if(is.numeric, round, 3) %>%
  mutate (remove = rowSums(is.na(.[,-c(1, 6, 8, 10)])),
          keep = ifelse (remove == 0, "Y", "N"))

dis_predictors_best <- dis_predictors %>%
  filter (keep == "Y")

```


## Performance

```{r}

dis_res <- 
cbind(Model = c("pval", "stepaic", "bestsubset",  "lasso", "ncvreg", "mboost", "mars"), 
      as.data.frame(do.call("rbind", list(res_m1, res_m2, res_m3, res_m4, res_m5, res_m6, res_m7)))
)
```

## Save

```{r}
dis_all_models <- list ("pval" = dis_m1, 
                       "stepaic" = dis_m2, 
                       "bestsubset" = dis_m3, 
                       "lasso"= dis_m4, 
                       "lasso_refit"= dis_m4_refit, 
                       "ncvreg"= dis_m5,
                       "ncvreg_refit"= dis_m5_refit,  
                       "mboost"= dis_m6, 
                       "mboost_refit"= dis_m6_refit,
                       "mars"= dis_m7)

dis <- list (performance = dis_res,
            predictors = dis_predictors,
            models = dis_all_models)

saveRDS(dis, "output/dis_iml.RDS")
```

# Report

```{r}
res_np <- readRDS("output/np_iml.RDS")
res_ap <- readRDS("output/ap_iml.RDS")
res_dis <- readRDS("output/dis_iml.RDS")
```

## Neck pain

```{r}

model_lvl <- c("pval", "pvalAdj", "stepaic", 
               "bestsubset","lasso", "ncvreg", "mboost", "mars")
model_names <- c("stepP", "stepPAdj", "stepAIC", 
                 "Best subset", "Lasso", "MCP", "mboost", "MuARS")

outcome_lvl <- c("Accuracy", "Precision", "Sensitivity", "Specificity", "AUC")

df.plot <- res_np$performance %>%
  pivot_longer(-Model, 
               names_to = "Outcomes",
               values_to = "val") %>%
  mutate (Model = factor (Model, model_lvl, model_names),
          Outcomes = factor (Outcomes, outcome_lvl))


f <- ggplot (df.plot) +
  geom_bar(aes (x = Outcomes, y = val, fill = Model),
           stat = "identity", position = "dodge") + 
  scale_fill_manual(values = c("#030303", "#EE6A50", "#FF0000", "#000080", "#00EE00", "#8B3E2F", "#4A4A4A", "#A6A6A6")) +
  ylim (0,1) + 
  ylab ("Value") +
  xlab ("Prediction measures") +
  theme_cowplot() 

tiff ("manuscript2/fig1.tiff", width = 8, height = 3, units = "in", res = 100)
f
dev.off()
```

```{r}
pred <- res_np$predictors %>%
  #dplyr::select (-c(remove, keep))  %>%
  mutate_if(is.numeric, round, 3) %>%
  dplyr::select(-mcp_refit) %>%
  mutate (Number = rowSums(!is.na(.[, c(2, 3, 4, 5, 6, 8, 9, 11)])))


pred[nrow(pred) + 1, 1] <- "Number"
pred[nrow(pred), -c(1, ncol(pred))] <- colSums(!is.na(pred[,-c(1, ncol(pred))]))

new_names <- c("Variables", "P-value", "P-valueAdj", "Step AIC", 
                  "Best subset", "Lasso", "Lasso refit",
                  "Ncvreg", "mboost", "mboost refit", "MuARS", "Number")

names (pred) <- new_names

new_variables <- c("Sex - female",
               "Age (years)",
               "Employment - not working",
               "Employment - working",
               "Duration of pain (days)",
               "Time since first episode (years) - 1-5",
               "Time since first episode (years) - 5â€“10",
               "Time since first episode (years) - >10",
               "Chronicity - chronic",
               "Baseline intensity of neck pain",
               "Baseline intensity of arm pain",
               "Baseline disability",
               "Diagnostic procedure: X-ray - yes",
               "Diagnostic procedure: MRI - yes",
               "Imaging findings: disc degeneration - yes",
               "Imaging findings: facet joint degeneration - yes",
               "Imaging findings: scoliosis - yes",
               "Imaging findings: spinal stenosis - yes",
               "Imaging findings: disc protrusion - yes",
               "Imaging findings: disc herniation - yes",
               "Pharmacological treatment: analgesics - yes",
               "Pharmacological treatment: NSAIDs - yes",
               "Pharmacological treatment: steroids - yes",
               "Pharmacological treatment: muscle relaxants - yes",
               "Pharmacological treatment: opioids - yes",
               "Pharmacological treatment: other treatments - yes",
               "Non pharmacological treatments - yes",
               "NRT",
               "Number")

pred$Variables <- new_variables
# Export to word
my_path <- paste0("manuscript2/Table 2",
                  ".docx")

ft <- flextable(pred) %>%
  width (1, 6, unit = "cm") %>%
  fontsize(size = 10) %>%
  set_caption(caption = "Table 2. Beta coefficients of selected variables for the outcome of neck pain",
              style = "Table Caption")

my_doc <- read_docx()  %>%
  body_add_flextable(ft) %>%
  body_end_section_landscape()

print (my_doc, target = my_path)
```

```{r}
probe <- df.plot %>%
  mutate(val = round (val, 3)) %>%
  pivot_wider(names_from = Outcomes,
              values_from = val)

apply (probe[,-1], 2, range)

apply (probe[,-1], 2, range) %>%
  apply(2, diff)

(mean((pred$Lasso[-nrow(pred)] - pred$`Lasso refit`[-nrow(pred)])/pred$`Lasso refit`[-nrow(pred)], na.rm = TRUE)) *100


(mean((pred$mboost[-nrow(pred)] - pred$`mboost refit`[-nrow(pred)])/pred$`mboost refit`[-nrow(pred)], na.rm = TRUE)) *100



probe <- pred %>%
  dplyr::select (- c(lasso, mboost, Number)) %>%
  mutate (Number = rowSums(!is.na(.[, -c (1)]))) %>%
  filter (Number == 8) %>%
  dplyr::select (-Number) %>%
  mutate (ave = rowMeans (.[,c(4:9)], na.rm = TRUE)) %>%
  mutate (diffP = ((pval - ave)/ave) * 100,
          diffPA = ((pvalAdj - ave)/ave) * 100) %>%
  summarize (meanP = mean (diffP),
             meanPA = mean (diffPA))

probe <- pred %>%
  dplyr::select (- c(lasso_refit, mboost_refit, Number)) %>%
  mutate (Number = rowSums(!is.na(.[, -c (1:3)]))) %>%
  mutate (Impt = ifelse ((is.na(pval) | is.na (pvalAdj)) & Number == 6, 1, 0 )) %>%
  filter (Impt == 1) 
```



## Arm pain

```{r}

df.plot <- res_ap$performance %>%
  pivot_longer(-Model, 
               names_to = "Outcomes",
               values_to = "val") %>%
  mutate (Model = factor (Model, model_lvl, model_names),
          Outcomes = factor (Outcomes, outcome_lvl))


f <- ggplot (df.plot) +
  geom_bar(aes (x = Outcomes, y = val, fill = Model),
           stat = "identity", position = "dodge") + 
  scale_fill_manual(values = c("#030303", "#EE6A50", "#FF0000", "#000080", "#00EE00", "#8B3E2F", "#4A4A4A", "#A6A6A6")) +
  ylim (0,1) + 
  ylab ("Value") +
  xlab ("Prediction measures") +
  theme_cowplot() 

tiff ("manuscript2/fig2.tiff", width = 8, height = 3, units = "in", res = 100)
f
dev.off()
```

```{r}
pred <- res_ap$predictors %>%
  #dplyr::select (-c(remove, keep))  %>%
  mutate_if(is.numeric, round, 3) %>%
  dplyr::select(-mcp_refit) %>%
  mutate (Number = rowSums(!is.na(.[, c(2, 3, 4, 5, 6, 8, 9, 11)])))

pred[nrow(pred) + 1, 1] <- "Number"
pred[nrow(pred), -c(1, ncol(pred))] <- as.integer(colSums(!is.na(pred[,-c(1, ncol(pred))])))


names (pred) <- new_names

pred$Variables <- new_variables
# Export to word
my_path <- paste0("manuscript2/Table 3",
                   ".docx")
ft <- flextable(pred) %>%
  width (1, 6, unit = "cm") %>%
   fontsize(size = 10) %>%
   set_caption(caption = "Table 3. Beta coefficients of selected variables for the outcome of arm pain",
               style = "Table Caption")

my_doc <- read_docx()  %>%
   body_add_flextable(ft) %>%
   body_end_section_landscape()

print (my_doc, target = my_path)
```

```{r}

probe <- df.plot %>%
  mutate(val = round (val, 3)) %>%
  pivot_wider(names_from = Outcomes,
              values_from = val)

apply (probe[,-1], 2, range)

apply (probe[,-1], 2, range) %>%
  apply(2, diff)


(mean((pred$Lasso[-nrow(pred)] - pred$`Lasso refit`[-nrow(pred)])/pred$`Lasso refit`[-nrow(pred)], na.rm = TRUE)) *100


(mean((pred$mboost[-nrow(pred)] - pred$`mboost refit`[-nrow(pred)])/pred$`mboost refit`[-nrow(pred)], na.rm = TRUE)) *100

probe <- pred %>%
  dplyr::select (- c(lasso, mboost, Number)) %>%
  mutate (Number = rowSums(!is.na(.[, -c (1)]))) %>%
  filter (Number == 8) %>%
  dplyr::select (-Number) %>%
  mutate (ave = rowMeans (.[,c(4:9)], na.rm = TRUE)) %>%
  mutate (diffP = ((pval - ave)/ave) * 100,
          diffPA = ((pvalAdj - ave)/ave) * 100) %>%
  summarize (meanP = mean (diffP),
             meanPA = mean (diffPA))

probe <- pred %>%
  dplyr::select (- c(lasso_refit, mboost_refit, Number)) %>%
  mutate (Number = rowSums(!is.na(.[, -c (1:3)]))) %>%
  mutate (Impt = ifelse ((is.na(pval) | is.na (pvalAdj)) & Number == 6, 1, 0 )) %>%
  filter (Impt == 1) 
```


## Disability

```{r}

df.plot <- res_dis$performance %>%
  pivot_longer(-Model, 
               names_to = "Outcomes",
               values_to = "val") %>%
  mutate (Model = factor (Model, model_lvl, model_names),
          Outcomes = factor (Outcomes, outcome_lvl))

f <- ggplot (df.plot) +
  geom_bar(aes (x = Outcomes, y = val, fill = Model),
           stat = "identity", position = "dodge") + 
  scale_fill_manual(values = c("#030303", "#EE6A50", "#FF0000", "#000080", "#00EE00", "#8B3E2F", "#4A4A4A", "#A6A6A6")) +
  ylim (0,1) + 
  ylab ("Value") +
  xlab ("Prediction measures") +
  theme_cowplot() 


tiff ("manuscript2/fig3.tiff", width = 8, height = 3, units = "in", res = 100)
f
dev.off()
```

```{r}
pred <- res_dis$predictors %>%
  #dplyr::select (-c(remove, keep))  %>%
  mutate_if(is.numeric, round, 3) %>%
  dplyr::select(-mcp_refit) %>%
  mutate (Number = rowSums(!is.na(.[, c(2, 3, 4, 5, 6, 8, 9, 11)])))

pred[nrow(pred) + 1, 1] <- "Number"
pred[nrow(pred), -c(1, ncol(pred))] <- as.integer(colSums(!is.na(pred[,-c(1, ncol(pred))])))

names (pred) <- new_names

pred$Variables <- new_variables


# Export to word
my_path <- paste0("manuscript2/Table 4",
                  ".docx")
ft <- flextable(pred) %>%
  width (1, 6, unit = "cm") %>%
  fontsize(size = 10) %>%
  set_caption(caption = "Table 4. Beta coefficients of selected variables for the outcome of disability",
              style = "Table Caption")

my_doc <- read_docx()  %>%
  body_add_flextable(ft) %>%
  body_end_section_landscape()

print (my_doc, target = my_path)
```

```{r}

probe <- df.plot %>%
  mutate(val = round (val, 3)) %>%
  pivot_wider(names_from = Outcomes,
              values_from = val)

apply (probe[,-1], 2, range)

apply (probe[,-1], 2, range) %>%
  apply(2, diff)

(mean((pred$Lasso[-nrow(pred)] - pred$`Lasso refit`[-nrow(pred)])/pred$`Lasso refit`[-nrow(pred)], na.rm = TRUE)) *100


(mean((pred$mboost[-nrow(pred)] - pred$`mboost refit`[-nrow(pred)])/pred$`mboost refit`[-nrow(pred)], na.rm = TRUE)) *100

probe <- pred %>%
  dplyr::select (- c(lasso, mboost, Number)) %>%
  mutate (Number = rowSums(!is.na(.[, -c (1)]))) %>%
  filter (Number == 8) %>%
  dplyr::select (-Number) %>%
  mutate (ave = rowMeans (.[,c(4:9)], na.rm = TRUE)) %>%
  mutate (diffP = ((pval - ave)/ave) * 100,
          diffPA = ((pvalAdj - ave)/ave) * 100) %>%
  summarize (meanP = mean (diffP),
             meanPA = mean (diffPA))

probe <- pred %>%
  dplyr::select (- c(lasso_refit, mboost_refit, Number)) %>%
  mutate (Number = rowSums(!is.na(.[, -c (1:3)]))) %>%
  mutate (Impt = ifelse ((is.na(pval) | is.na (pvalAdj)) & Number == 6, 1, 0 )) %>%
  filter (Impt == 1) 
```
